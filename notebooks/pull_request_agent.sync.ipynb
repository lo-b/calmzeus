{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25e66f48",
   "metadata": {},
   "source": [
    "# Exploration of simple pull request (PR) agent\n",
    "\n",
    "## Intro\n",
    "How to go from LLM response/answer to a commit (and PR)?\n",
    "\n",
    "- One way could be to create an agent. It could extract only relevant text in\n",
    "an answer and then use this to make the commit for a config task.\n",
    "- Another way could be to try playing around with the prompt to get a more\n",
    "exact/concise output.\n",
    "- Exploring possibility simple (A)ST-based indexing of source files.\n",
    "Ensures we keep track of the actual lines in source file of a snippet. Feed\n",
    "al this context forward into the LLM. Maybe it can use the additional (e.g.\n",
    "line number) context to be more precise in it's output.\n",
    "\n",
    "In this notebook, CST enrichment (for details see\n",
    "[here](./cst_indexing.sync.ipynb)) + prompt engineering is used.\n",
    "\n",
    "## Goal\n",
    "Create an agent/chain to extract relevant code/text from LLM answer and\n",
    "create a commit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b49791",
   "metadata": {},
   "source": [
    "# Exploration\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25113330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import (\n",
    "    RunnablePassthrough,\n",
    "    RunnableSerializable,\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from langchain_voyageai import VoyageAIEmbeddings\n",
    "from qdrant_client import QdrantClient\n",
    "from typing_extensions import Never"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9c43b2",
   "metadata": {},
   "source": [
    "## Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f01a5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "QDRANT_COLLECTION_NAME = \"simple-java-api\"\n",
    "VOYAGE_MODEL_NAME = \"voyage-code-2\"\n",
    "MISTRAL_MODEL_NAME = \"open-codestral-mamba\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de977643",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert load_dotenv(), \".env files exists and contains at least one variable\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690fab0f",
   "metadata": {},
   "source": [
    "## Create (core) RAG flow\n",
    "Consists of:\n",
    "- indexing\n",
    "- retrieval\n",
    "- generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210ff7ef",
   "metadata": {},
   "source": [
    "### Indexing & retrieval\n",
    "Load documents and enrich their metadata with *context syntax trees* (CSTs).\n",
    "Add docs to vector store and create a retriever for the store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba53fd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = VoyageAIEmbeddings(model=VOYAGE_MODEL_NAME, batch_size=1)\n",
    "\n",
    "client = QdrantClient(\n",
    "    url=f\"https://{os.environ['QDRANT_CLUSTER_ENDPOINT']}:6333\",\n",
    "    api_key=os.environ[\"QDRANT_API_KEY\"],\n",
    ")\n",
    "\n",
    "vector_store = QdrantVectorStore(\n",
    "    client=client,\n",
    "    collection_name=QDRANT_COLLECTION_NAME,\n",
    "    embedding=embeddings,\n",
    ")\n",
    "\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\"k\": 4, \"fetch_k\": 5, \"lambda_mult\": 0.25},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5113224f",
   "metadata": {},
   "source": [
    "### Rephrase question\n",
    "Implement small chain to rephrase a user's question -- ideally to find a\n",
    "more similar document. Using [GPT-4o mini](\n",
    "https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/\n",
    ") to rephrase question. As of writing, costs are as following:\n",
    "|in- or output|cost per million (1M) tokens|\n",
    "|---|---|\n",
    "|input|\\$0.150|\n",
    "|output|\\$0.600|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b109ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt: PromptTemplate = hub.pull(\"lo-b/rag-rephrase-assist-prompt\")\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "rephraser: RunnableSerializable[Never, str] = (\n",
    "    {\"question\": RunnablePassthrough()} | prompt | llm | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf89ab46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This file can be used to change the application development port.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rephraser.invoke(\"Change app dev port to 7777\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
